## Blog

Shared experiments to understand LLMs and how we may tame them. 

- [small world models (5th May 2025)](test.md) : LLMs are terrible at visual reasoning and cannot even reason around basic visual puzzles. 
There is a [million dollar prize](https://www.arcprize.org) to anyone who can make them 85% accurate on visual puzzles that are very simple for humans.
These puzzles use simple concepts such as copying, moving, colliding, large eats small etc. in a small world to create scenarios. 
To solve this, we need to find the precise program which will generate a scenario and apply it to a another instance of that world to solve a puzzle. 
This blog has my ideas, and attempts to solve this problem. 


- [state of video understanding and analytics (5th May 2025)](video.md) : 


- [agents see agent do](agents.md): how to build agents that learn by looking at you work 